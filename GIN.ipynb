{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINConv(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        \"\"\"\n",
    "        Params\n",
    "        ------\n",
    "            A [nodes x nodes]: adjacency matrix\n",
    "        \n",
    "            X [nodes x features]: node features matrix\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            X' [nodes x features]: updated node features matrix\n",
    "        \"\"\"\n",
    "        X = self.linear(X + A @ X)\n",
    "        X = torch.nn.functional.relu(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.pyenv/versions/3.7.3/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.binomial_graph(5,0.5)\n",
    "\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor( nx.adjacency_matrix(G).todense(), dtype=torch.float32 )\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1727, -0.2404],\n",
       "        [-0.4266,  0.0049],\n",
       "        [-0.8128, -0.1084],\n",
       "        [ 1.0900,  0.9147],\n",
       "        [-0.3288,  0.1470]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(5,2)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3948, 0.0000],\n",
       "        [0.7098, 0.0000],\n",
       "        [0.9193, 0.0000],\n",
       "        [1.0761, 0.0000],\n",
       "        [1.2201, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GINConv(2).forward(A,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3054,  0.7178, -0.3054,  0.7178]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([X,X],dim=1).sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "import importlib  \n",
    "gnns = importlib.import_module('powerful-gnns.util')\n",
    "\n",
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    \"\"\" Levanta los datasets de Powerful-GNNS. \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset='PROTEINS', degree_as_tag=False):\n",
    "        self.data = gnns.load_data(dataset, degree_as_tag)[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        \n",
    "        item['node_features'] = self.data[idx].node_features\n",
    "        item['adjacency_matrix'] = torch.tensor(nx.adjacency_matrix( self.data[idx].g ).todense(), dtype=torch.float32)\n",
    "        item['class'] = self.data[idx].label\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_proj = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        for _ in range(n_layers):\n",
    "            self.convs.append(GINConv(hidden_dim))\n",
    "        \n",
    "        # In order to perform graph classification, each hidden state\n",
    "        # [nodes x hidden_dim] is aggregated along nodes dimension,\n",
    "        # resulting in [hidden_dim], concatenated [hidden_dim x (1+n_layers)]\n",
    "        # and then fed to the output layer.\n",
    "        self.out_proj = torch.nn.Linear(hidden_dim*(1+n_layers), output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, A, X):\n",
    "        X = self.in_proj(X)\n",
    "\n",
    "        hidden_states = [X]\n",
    "        \n",
    "        for layer in self.convs:\n",
    "            X = layer(A, X)\n",
    "            hidden_states.append(X)\n",
    "\n",
    "        X = torch.cat(hidden_states, dim=2).sum(dim=1)\n",
    "\n",
    "        X = self.out_proj(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN(input_dim=3, hidden_dim=2, output_dim=2, n_layers=1)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "# classes: 2\n",
      "# maximum node tag: 3\n",
      "# data: 1113\n"
     ]
    }
   ],
   "source": [
    "ds = GraphDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pass\n",
    "\n",
    "dl = torch.utils.data.DataLoader(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 161.581\n",
      "[1,    40] loss: 0.545\n",
      "[1,    60] loss: 0.500\n",
      "[1,    80] loss: 0.751\n",
      "[1,   100] loss: 0.516\n",
      "[1,   120] loss: 0.239\n",
      "[1,   140] loss: 0.168\n",
      "[1,   160] loss: 0.037\n",
      "[1,   180] loss: 0.208\n",
      "[1,   200] loss: 0.090\n",
      "[1,   220] loss: 0.169\n",
      "[1,   240] loss: 0.078\n",
      "[1,   260] loss: 0.068\n",
      "[1,   280] loss: 0.011\n",
      "[1,   300] loss: 0.025\n",
      "[1,   320] loss: 0.051\n",
      "[1,   340] loss: 0.088\n",
      "[1,   360] loss: 0.208\n",
      "[1,   380] loss: 0.092\n",
      "[1,   400] loss: 0.146\n",
      "[1,   420] loss: 0.423\n",
      "[1,   440] loss: 0.034\n",
      "[1,   460] loss: 0.242\n",
      "[1,   480] loss: 0.017\n",
      "[1,   500] loss: 0.012\n",
      "[1,   520] loss: 0.090\n",
      "[1,   540] loss: 0.024\n",
      "[1,   560] loss: 0.179\n",
      "[1,   580] loss: 0.061\n",
      "[1,   600] loss: 0.004\n",
      "[1,   620] loss: 0.035\n",
      "[1,   640] loss: 0.012\n",
      "[1,   660] loss: 0.016\n",
      "[1,   680] loss: 80.375\n",
      "[1,   700] loss: 22.443\n",
      "[1,   720] loss: 1.072\n",
      "[1,   740] loss: 0.587\n",
      "[1,   760] loss: 0.545\n",
      "[1,   780] loss: 0.244\n",
      "[1,   800] loss: 0.300\n",
      "[1,   820] loss: 0.278\n",
      "[1,   840] loss: 0.274\n",
      "[1,   860] loss: 0.364\n",
      "[1,   880] loss: 0.510\n",
      "[1,   900] loss: 0.447\n",
      "[1,   920] loss: 0.282\n",
      "[1,   940] loss: 0.321\n",
      "[1,   960] loss: 0.403\n",
      "[1,   980] loss: 0.268\n",
      "[1,  1000] loss: 0.101\n",
      "[1,  1020] loss: 0.208\n",
      "[1,  1040] loss: 0.110\n",
      "[1,  1060] loss: 0.451\n",
      "[1,  1080] loss: 0.208\n",
      "[1,  1100] loss: 0.206\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dl):\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(data['adjacency_matrix'],data['node_features'])\n",
    "        loss = criterion(outputs, data['class'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
